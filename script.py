# -*- coding: utf-8 -*-
"""Copy of CUAD_extraction_and_segmentation_clean.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pnIvhz1va2LZ8XT1M_s4T6kaZkSQDlUO

### Installation
"""

# !pip install pymupdf
# !pip install Unidecode

import numpy as np
import pandas as pd

from operator import itemgetter
import fitz
import json

import re 
from unidecode import unidecode

import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.tokenize import word_tokenize, sent_tokenize
import gensim

def load_file(my_file):
  doc = fitz.open(my_file)
  return doc

def remove_empty(df):
  df = df.reset_index(drop=True)

  for i in range(len(df)-1):
      if df.at[i, 'content'] == '' and df.at[i, 'heading'] != '':
          df.at[i+1, 'heading'] = df.at[i, 'heading'] + '. ' + df.at[i+1, 'heading']
          df.drop(i, inplace=True)
    
      elif df.at[i, 'heading'] == '' and df.at[i, 'content'] != '':
          df.at[i+1, 'content'] = df.at[i, 'content'] + '. ' + df.at[i+1, 'content']
          df.drop(i, inplace=True)

  return df

def split_section_num(df):
# Define a regex pattern to detect section numbers
  section_pattern = re.compile(r'^\s*(\d*\.\s+|\d*\.|M{0,3}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})\.\s+|M{0,3}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})\.)+')

  # Define an empty list to store the results
  result = []

  # Iterate over the rows of the dataframe
  for _, row in df.iterrows():
    
      # Split the content column into individual sentences
      sentences = row['content'].split('\n')

      # Define a variable to store the heading
      heading = None
      
      # Iterate over the sentences
      for sentence in sentences:
          # Check if the sentence is a section heading
          if section_pattern.match(sentence):
              # If it is, set the heading variable to the first sentence
              heading = sentence
              
              # Append the section heading as a new row to the result list
              result.append({
                  'heading': heading,
                  'content': ''
              })
          elif heading:
              # If there is a heading, append the sentence to the content of the previous section
              result[-1]['content'] += sentence + '\n'
          
          else:
              # If there is no heading, keep the original heading and add the sentence to the content
              if any(r['heading'] == row['heading'] for r in result):
                  # If a row with the same heading already exists, append the content to its existing content
                  result[-1]['content'] += '\n' + sentence
              else:
                  # Otherwise, create a new row with the original heading and the sentence as the content
                  result.append({
                      'heading': row['heading'],
                      'content': sentence
                  })

  # Convert the result list to a new dataframe
  new_df = pd.DataFrame(result)

  return new_df

def extract_segement(doc):

  doc = load_file(doc)

  # get the spans from the PDF file
  block_dict = {}

  page_num = 1
  for page in doc: # Iterate all pages in the document
        file_dict = page.get_text('dict') # Get the page dictionary 
        block = file_dict['blocks'] # Get the block information
        block_dict[page_num] = block # Store in block dictionary
        page_num += 1 # Increase the page value by 1

  # create a dictionary containing detailed information of all spans in the document and store in a DataFrame
  spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])
  rows = []

  for page_num, blocks in block_dict.items():
      for block in blocks:
          if block['type'] == 0:
              for line in block['lines']:
                  for span in line['spans']:
                      xmin, ymin, xmax, ymax = list(span['bbox'])
                      font_size = span['size']
                      text = unidecode(span['text'])
                      span_font = span['font']
                      
                      is_upper = False
                      is_bold = False                     

                      if "bold" in span_font.lower():
                          is_bold = True 
                      if re.sub("[\(\[].*?[\)\]]", "", text).isupper():
                          is_upper = True                 
                      if text.replace(" ","") !=  "":
                          rows.append((xmin, ymin, xmax, ymax, text, is_upper, is_bold, span_font, font_size))
                          
  span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text', 'is_upper','is_bold','span_font', 'font_size'])

  # create more features
  """
  The ‘h’ tag denotes the text which is bigger and more important than normal paragraphs. (e.g. UPPER CASE and bold style)
  The ‘p’ tag stands for paragraph, or the normal content in the document. 
  The ‘s’ tag will be used for less important text, which is smaller than ‘p’ text.
  """

  span_scores = []
  span_num_occur = {}
  special = '[(_:/,#%\=@)]'

  for index, span_row in span_df.iterrows():    
      score = round(span_row.font_size)
      text = span_row.text    
      if not re.search(special, text):       
          if span_row.is_bold:
              score +=1 
          if span_row.is_upper:
              score +=1
      span_scores.append(score)

  values, counts = np.unique(span_scores, return_counts=True)
  style_dict = {}

  for value, count in zip(values, counts):
      style_dict[value] = count

  sorted(style_dict.items(), key=lambda x: x[1])

  p_size = max(style_dict, key=style_dict.get)
  idx = 0
  tag = {}

  for size in sorted(values, reverse = True):
      idx += 1
      if size == p_size:
          idx = 0
          tag[size] = 'p'
      if size > p_size:
          tag[size] = 'h{0}'.format(idx)
      if size < p_size:
          tag[size] = 's{0}'.format(idx)

  span_tags = [tag[score] for score in span_scores]
  span_df['tag'] = span_tags

  # define headings and paragraphs in the document
  headings_list = []
  text_list = []
  tmp = []
  heading = ''                                                                                                                

  for index, span_row in span_df.iterrows():
      text = span_row.text
      tag = span_row.tag
      if 'h' in tag:
        if len(text) < 70:
          headings_list.append(text)
          text_list.append('\n'.join(tmp)) 
          tmp = []
          heading = text
        else:
          tmp.append(text) 
      else:
          tmp.append(text)

  text_list.append('\n'.join(tmp))
  text_list = text_list[1:]
  text_df = pd.DataFrame(zip(headings_list, text_list),columns=['heading', 'content'] )

  # combine the empty cells
  text_df = remove_empty(text_df)

  # split the section number out
  new_df = split_section_num(text_df)

  # combine the empty cells
  new_df = remove_empty(new_df)

  return(list(new_df['heading'] + " " + new_df['content']))